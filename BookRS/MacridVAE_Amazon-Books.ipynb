{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_loss(inputs, logits):\n",
    "    return torch.mean(torch.sum(-logits * inputs, dim=1))\n",
    "\n",
    "def kl_loss(mu, logvar):\n",
    "    return torch.mean(0.5 * torch.sum(\n",
    "        torch.exp(logvar) + mu ** 2 - 1 - logvar, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisenVAE(nn.Module):\n",
    "    def __init__(self, M, K, D, tau, dropout):\n",
    "        super(DisenVAE, self).__init__()\n",
    "\n",
    "        self.M = M\n",
    "        self.H = D * 3\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "        self.tau = tau\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.M, self.H),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.H, self.D * 2)\n",
    "        )\n",
    "        self.items = Parameter(torch.Tensor(self.M, self.D))\n",
    "        self.cores = Parameter(torch.Tensor(self.K, self.D))\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        init.xavier_normal_(self.items)\n",
    "        init.xavier_normal_(self.cores)\n",
    "\n",
    "\n",
    "    def cluster(self):\n",
    "        items = F.normalize(self.items, dim=1)      # M * D\n",
    "        cores = F.normalize(self.cores, dim=1)      # K * D\n",
    "        cates = torch.mm(items, cores.t()) / self.tau\n",
    "        cates = F.softmax(cates, dim=1)             # M * K\n",
    "        return items, cores, cates\n",
    "\n",
    "\n",
    "    def encode(self, X, cates):\n",
    "        n = X.shape[0]\n",
    "        X = self.drop(X)\n",
    "        X = X.view(n, 1, self.M) *  \\\n",
    "            cates.t().expand(n, self.K, self.M)     # n * K * M\n",
    "        X = X.reshape(n * self.K, self.M)           # (n * K) * M\n",
    "        h = self.encoder(X)                         # (n * K) * D * 2\n",
    "        mu, logvar = h[:, :self.D], h[:, self.D:]   # (n * k) * D\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "    def decode(self, z, items, cates):\n",
    "        n = z.shape[0] // self.K\n",
    "        z = F.normalize(z, dim=1)                   # (n * K) * D\n",
    "        logits = torch.mm(z, items.t()) / self.tau  # (n * K) * M\n",
    "        probs = torch.exp(logits)                   # (n * K) * M\n",
    "        probs = torch.sum(probs.view(n, self.K, self.M) * \\\n",
    "                cates.t().expand(n, self.K, self.M), dim=1)\n",
    "        logits = torch.log(probs)\n",
    "        logits = F.log_softmax(logits, dim=1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def sample(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + std * eps\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        items, cores, cates = self.cluster()\n",
    "        mu, logvar = self.encode(X, cates)\n",
    "        z = self.sample(mu, logvar)\n",
    "        logits = self.decode(z, items, cates)\n",
    "        return logits, mu, logvar, None, None, None\n",
    "    \n",
    "\n",
    "    def loss_fn(self, X, X_logits, X_mu, X_logvar,\n",
    "                A, A_logits, A_mu, A_logvar, anneal):\n",
    "        return recon_loss(X, X_logits) + anneal * kl_loss(X_mu, X_logvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k)  Recall@k and Precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_kth(outputs, labels, k=100):\n",
    "    _, preds = torch.topk(outputs, k)               # sorted top k index of outputs\n",
    "    _, facts = torch.topk(labels, k)                # min(k, labels.nnz(dim=1))\n",
    "    rows = torch.arange(labels.shape[0]).view(-1, 1)\n",
    "\n",
    "    tp = 1.0 / torch.log2(torch.arange(2, k + 2).float())\n",
    "    dcg = torch.sum(tp * labels[rows, preds], dim=1)\n",
    "    idcg = torch.sum(tp * labels[rows, facts], dim=1)\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0\n",
    "    return ndcg\n",
    "\n",
    "\n",
    "def recall_kth(outputs, labels, k=50):\n",
    "    _, preds = torch.topk(outputs, k, sorted=False) # top k index\n",
    "    rows = torch.arange(labels.shape[0]).view(-1, 1)\n",
    "\n",
    "    recall = torch.sum(labels[rows, preds], dim=1) \\\n",
    "           / torch.min(torch.Tensor([k]), torch.sum(labels, dim=1))\n",
    "    recall[torch.isnan(recall)] = 0\n",
    "    return recall\n",
    "\n",
    "def precision_kth(outputs, labels, k=50):\n",
    "    \"\"\"\n",
    "    Compute Precision@k: the proportion of positive class predictions in the top-k predictions\n",
    "    that are correct.\n",
    "    \n",
    "    Args:\n",
    "    - outputs (torch.Tensor): The model outputs (scores or probabilities) for each class.\n",
    "    - labels (torch.Tensor): The ground truth labels (binary) for each sample.\n",
    "    - k (int): The number of top predictions to consider for computing precision.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: Precision@k for each sample in the batch.\n",
    "    \"\"\"\n",
    "    # Get the index of the top k highest scoring predictions\n",
    "    _, preds = torch.topk(outputs, k, sorted=False)  # top k index\n",
    "    \n",
    "    # Generate a row index for each sample\n",
    "    rows = torch.arange(labels.shape[0]).view(-1, 1)\n",
    "\n",
    "    # Compute Precision@k\n",
    "    # Get the actual labels by indexing and calculate the number of correct predictions for each sample\n",
    "    correct_preds = torch.sum(labels[rows, preds], dim=1)\n",
    "    precision = correct_preds / k\n",
    "    precision[torch.isnan(precision)] = 0\n",
    "    \n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = r'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(processed_dataset, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "n_items = len(unique_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = list()\n",
    "with open(os.path.join(processed_dataset, 'unique_uid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_uid.append(line.strip())\n",
    "n_users = len(unique_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(csv_file, n_items):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                              (rows, cols)), dtype='float64',\n",
    "                             shape=(users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(processed_dataset, 'train.csv'), n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te, n_items):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                                 (rows_tr, cols_tr)), dtype='float64',\n",
    "                                shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                                 (rows_te, cols_te)), dtype='float64',\n",
    "                                shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(\n",
    "        os.path.join(processed_dataset, 'validation_tr.csv'),\n",
    "        os.path.join(processed_dataset, 'validation_te.csv'),\n",
    "        n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_data_tr, tst_data_te = load_tr_te_data(\n",
    "        os.path.join(processed_dataset, 'test_tr.csv'),\n",
    "        os.path.join(processed_dataset, 'test_te.csv'),\n",
    "        n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n_items == train_data.shape[1]\n",
    "assert n_items == vad_data_tr.shape[1]\n",
    "assert n_items == vad_data_te.shape[1]\n",
    "assert n_items == tst_data_tr.shape[1]\n",
    "assert n_items == tst_data_te.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "weight_decay = 1e-4 # weight decay coefficient\n",
    "dropout = 0.5\n",
    "beta = 0.2\n",
    "kfac = 7\n",
    "dfac = 200\n",
    "tau = 0.1\n",
    "batch_size = 400\n",
    "epochs = 50\n",
    "total_anneal_steps = 200000 # the total number of gradient updates for annealing\n",
    "anneal_cap = 0.2 \n",
    "seed = 98765 # random seed\n",
    "log_interval = 100\n",
    "save = r'model.pt' # path to save the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f03ff6c28b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed) # Set the random seed manually for reproductibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  \n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  \n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(model, N, M, K, D, tau, dropout):\n",
    "    if model == 'DisenVAE':\n",
    "        return DisenVAE(M, K, D, tau, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DisenVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=146336, out_features=600, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=600, out_features=400, bias=True)\n",
       "  )\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = load_net('DisenVAE', n_users, n_items, kfac, dfac, \n",
    "               tau, dropout)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = net.loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a MacridVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg100_values = []\n",
    "\n",
    "empty_data = sparse.csr_matrix(train_data.shape, dtype=float)\n",
    "tr_data = sparse.vstack([train_data, vad_data_tr, tst_data_tr])\n",
    "te_data = sparse.vstack([empty_data, vad_data_te, tst_data_te])\n",
    "\n",
    "n_train = train_data.shape[0]\n",
    "n_valid = vad_data_tr.shape[0]\n",
    "n_test  = tst_data_tr.shape[0]\n",
    "train_idx = range(n_train)\n",
    "valid_idx = range(n_train, n_train + n_valid)\n",
    "test_idx  = range(n_train + n_valid, n_train + n_valid + n_test)\n",
    "\n",
    "n_batches = int(np.ceil(n_train / batch_size))\n",
    "update = 0\n",
    "anneals = 500 * n_batches\n",
    "best_n100 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, idx):\n",
    "    net.eval()\n",
    "    n_test = len(idx)\n",
    "    metrics = {'ndcg': {}, 'recall': {}, 'precision': {}}\n",
    "    ks = [5, 10, 20, 50, 100]\n",
    "\n",
    "    # Initialising the metrics store\n",
    "    for k in ks:\n",
    "        metrics['ndcg'][k] = []\n",
    "        metrics['recall'][k] = []\n",
    "        metrics['precision'][k] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, n_test, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, n_test)\n",
    "            X_tr = tr_data[idx[start_idx: end_idx]]\n",
    "            X_te = te_data[idx[start_idx: end_idx]]\n",
    "            X_tr = torch.Tensor(X_tr.toarray()).to(device)\n",
    "            X_te = torch.Tensor(X_te.toarray())\n",
    "            A = None\n",
    "            X_tr_logits, _, _, _, _, _ = net(X_tr, A)\n",
    "\n",
    "            X_tr_logits[torch.nonzero(X_tr, as_tuple=True)] = float('-inf')\n",
    "            X_tr_logits = X_tr_logits.cpu()\n",
    "\n",
    "            # Calculation of indicators\n",
    "            for k in ks:\n",
    "                metrics['ndcg'][k].append(ndcg_kth(X_tr_logits, X_te, k=k))\n",
    "                metrics['recall'][k].append(recall_kth(X_tr_logits, X_te, k=k))\n",
    "                metrics['precision'][k].append(precision_kth(X_tr_logits, X_te, k=k))\n",
    "\n",
    "    # Converting a list of indicators to an average\n",
    "    for metric in metrics:\n",
    "        for k in ks:\n",
    "            metrics[metric][k] = torch.mean(torch.cat(metrics[metric][k])).item()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0] loss: 592.887\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   0 | time: 49.59s | ndcg@100 0.029 | recall@20 0.019 | recall@50 0.035\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  1] loss: 530.510\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 48.50s | ndcg@100 0.069 | recall@20 0.052 | recall@50 0.087\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  2] loss: 489.634\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 48.57s | ndcg@100 0.104 | recall@20 0.082 | recall@50 0.130\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  3] loss: 466.264\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 48.77s | ndcg@100 0.126 | recall@20 0.103 | recall@50 0.158\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  4] loss: 446.938\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 48.65s | ndcg@100 0.147 | recall@20 0.120 | recall@50 0.181\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  5] loss: 429.678\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 48.48s | ndcg@100 0.163 | recall@20 0.135 | recall@50 0.197\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  6] loss: 417.231\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 48.82s | ndcg@100 0.173 | recall@20 0.145 | recall@50 0.210\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  7] loss: 409.168\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 48.76s | ndcg@100 0.178 | recall@20 0.150 | recall@50 0.218\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  8] loss: 404.672\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 48.81s | ndcg@100 0.183 | recall@20 0.154 | recall@50 0.222\n",
      "-----------------------------------------------------------------------------------------\n",
      "[  9] loss: 399.737\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 48.90s | ndcg@100 0.184 | recall@20 0.153 | recall@50 0.226\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 10] loss: 396.684\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 48.96s | ndcg@100 0.185 | recall@20 0.156 | recall@50 0.226\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 11] loss: 396.356\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 48.57s | ndcg@100 0.185 | recall@20 0.159 | recall@50 0.228\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 12] loss: 393.931\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 48.36s | ndcg@100 0.186 | recall@20 0.158 | recall@50 0.229\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 13] loss: 393.712\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 49.03s | ndcg@100 0.185 | recall@20 0.157 | recall@50 0.228\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 14] loss: 392.827\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 48.52s | ndcg@100 0.185 | recall@20 0.156 | recall@50 0.228\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 15] loss: 392.827\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 48.23s | ndcg@100 0.187 | recall@20 0.157 | recall@50 0.229\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 16] loss: 393.180\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 48.61s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.227\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 17] loss: 392.610\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 48.18s | ndcg@100 0.186 | recall@20 0.157 | recall@50 0.230\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 18] loss: 392.261\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 48.35s | ndcg@100 0.187 | recall@20 0.159 | recall@50 0.229\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 19] loss: 393.807\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 48.63s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.229\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 20] loss: 393.273\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 48.53s | ndcg@100 0.187 | recall@20 0.157 | recall@50 0.227\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 21] loss: 392.529\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 48.82s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.229\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 22] loss: 392.863\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 48.66s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.229\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 23] loss: 394.001\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 48.74s | ndcg@100 0.186 | recall@20 0.158 | recall@50 0.229\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 24] loss: 392.977\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 48.68s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.228\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 25] loss: 393.535\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 48.55s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.227\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 26] loss: 393.449\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 48.48s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.228\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 27] loss: 393.981\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 47.93s | ndcg@100 0.184 | recall@20 0.155 | recall@50 0.225\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 28] loss: 394.133\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 48.69s | ndcg@100 0.187 | recall@20 0.158 | recall@50 0.226\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 29] loss: 394.539\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 48.65s | ndcg@100 0.186 | recall@20 0.154 | recall@50 0.225\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 30] loss: 395.090\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 48.50s | ndcg@100 0.184 | recall@20 0.155 | recall@50 0.226\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 31] loss: 395.829\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 48.10s | ndcg@100 0.184 | recall@20 0.157 | recall@50 0.227\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 32] loss: 395.649\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 48.72s | ndcg@100 0.184 | recall@20 0.155 | recall@50 0.226\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 33] loss: 395.783\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 48.93s | ndcg@100 0.185 | recall@20 0.155 | recall@50 0.225\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 34] loss: 398.247\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 48.58s | ndcg@100 0.184 | recall@20 0.154 | recall@50 0.226\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 35] loss: 396.524\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 48.43s | ndcg@100 0.184 | recall@20 0.154 | recall@50 0.226\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 36] loss: 396.503\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 48.54s | ndcg@100 0.182 | recall@20 0.154 | recall@50 0.225\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 37] loss: 397.733\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 48.55s | ndcg@100 0.183 | recall@20 0.154 | recall@50 0.224\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 38] loss: 397.722\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 48.69s | ndcg@100 0.183 | recall@20 0.155 | recall@50 0.225\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 39] loss: 397.739\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 48.45s | ndcg@100 0.183 | recall@20 0.155 | recall@50 0.222\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 40] loss: 397.761\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 48.39s | ndcg@100 0.183 | recall@20 0.155 | recall@50 0.222\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 41] loss: 398.064\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 49.01s | ndcg@100 0.181 | recall@20 0.153 | recall@50 0.221\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 42] loss: 399.930\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 48.74s | ndcg@100 0.180 | recall@20 0.151 | recall@50 0.221\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 43] loss: 398.692\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 48.60s | ndcg@100 0.181 | recall@20 0.152 | recall@50 0.221\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 44] loss: 398.551\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 48.63s | ndcg@100 0.181 | recall@20 0.154 | recall@50 0.221\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 45] loss: 400.330\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 48.72s | ndcg@100 0.181 | recall@20 0.152 | recall@50 0.221\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 46] loss: 399.888\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 48.59s | ndcg@100 0.181 | recall@20 0.154 | recall@50 0.221\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 47] loss: 399.618\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 48.62s | ndcg@100 0.180 | recall@20 0.152 | recall@50 0.219\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 48] loss: 400.173\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 48.32s | ndcg@100 0.179 | recall@20 0.151 | recall@50 0.219\n",
      "-----------------------------------------------------------------------------------------\n",
      "[ 49] loss: 400.119\t-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 48.68s | ndcg@100 0.179 | recall@20 0.150 | recall@50 0.218\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        t = time.time()\n",
    "        \n",
    "        train_idx = np.random.permutation(train_idx)\n",
    "        \n",
    "        for start_idx in range(0, n_train, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, n_train)\n",
    "            X = train_data[train_idx[start_idx: end_idx]]\n",
    "            X = torch.Tensor(X.toarray()).to(device)  # users-items matrix\n",
    "            A = None\n",
    "            optimizer.zero_grad()\n",
    "            X_logits, X_mu, X_logvar, A_logits, A_mu, A_logvar = net(X, A)\n",
    "            anneal = min(beta, update / anneals)\n",
    "            loss = criterion(X, X_logits, X_mu, X_logvar, A, A_logits, A_mu, A_logvar, anneal)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            update += 1\n",
    "        \n",
    "        print('[%3d] loss: %.3f' % (epoch, running_loss / n_batches), end='\\t', flush=True)\n",
    "        # Evaluation \n",
    "        metrics = evaluate(net, valid_idx)\n",
    "        ndcg100_values.append(metrics['ndcg'][100]) \n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:4.2f}s | '\n",
    "            'ndcg@100 {:5.3f} | recall@20 {:5.3f} | recall@50 {:5.3f}'.format(\n",
    "                epoch, time.time() - epoch_start_time, \n",
    "                metrics['ndcg'][100], metrics['recall'][20], metrics['recall'][50]))\n",
    "        print('-' * 89)\n",
    "\n",
    "        # Save the model if the n100 is the best we've seen so far.\n",
    "        if metrics['ndcg'][100] > best_n100:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(net, f)\n",
    "            best_n100 = metrics['ndcg'][100]    \n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(save, 'rb') as f:\n",
    "    model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ndcg100_values, label='NDCG@100')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('NDCG@100')\n",
    "plt.title('NDCG@100 on Validation Set Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training |\n",
      "| ndcg@5 0.115 | recall@5 0.107 | precision@5 0.102\n",
      "| ndcg@10 0.117 | recall@10 0.117 | precision@10 0.081\n",
      "| ndcg@20 0.128 | recall@20 0.146 | precision@20 0.059\n",
      "| ndcg@50 0.153 | recall@50 0.213 | precision@50 0.037\n",
      "| ndcg@100 0.174 | recall@100 0.278 | precision@100 0.026\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run on test data.\n",
    "metrics = evaluate(net, test_idx)\n",
    "\n",
    "print('=' * 89)\n",
    "print('| End of training |')\n",
    "for k in [5, 10, 20, 50, 100]:\n",
    "    print('| ndcg@{} {:5.3f} | recall@{} {:5.3f} | precision@{} {:5.3f}'.format(\n",
    "        k, metrics['ndcg'][k], k, metrics['recall'][k], k, metrics['precision'][k]))\n",
    "print('=' * 89)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
